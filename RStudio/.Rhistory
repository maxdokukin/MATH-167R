labs(title = "Transactions Counts vs Very Good Decisions",
x = "Total Transactions",
y = "Proportion of Very Good Decisions (%)")
# prepare data
plot_data <- politician_info_df |>
filter(Total_Transactions < 500) |>
filter(Total_Transactions > 10 ) |>
filter(Proportion_of_Very_Good_Decisions > 35) |>
mutate(label = sprintf("%s (%.2f%%)", Politician.Name, Proportion_of_Very_Good_Decisions))
ggplot(plot_data, aes(y = Total_Transactions,
x = Proportion_of_Very_Good_Decisions,
color = Party)) +
# main data
geom_point() +
geom_text(aes(label = label),
nudge_x = 1.8,
nudge_y = 0.5,
size = 2,
check_overlap = TRUE) +
scale_color_manual(values = party_colors) +  # Define custom colors for the groups
# theme
dark_theme() +
# labels
labs(title = "Very Good Decisions vs Transactions Counts",
x = "Proportion of Very Good Decisions (%)",
y = "Total Transactions")
xlim(35, 55)
# binom test on the proportion of very good decisions
tst_data <- politician_info_df[!is.na(politician_info_df$`Very Good Decision`), ]
tst_results <- tst_data |>
rowwise() |>
mutate(
test_result = list(binom.test(x = `Very Good Decision`, n = Total_Transactions, p = 0.25)),
p_value = test_result$p.value,
statistic = test_result$statistic
) |>
ungroup()
sig_results <- tst_results %>%
filter(p_value < 0.05, Proportion_of_Very_Good_Decisions > 25) |>
arrange(desc(Proportion_of_Very_Good_Decisions)) |>
select(`Politician.Name`, Total_Transactions, Proportion_of_Very_Good_Decisions, p_value)
print(sig_results)
write.csv(sig_results, "sus_poltics.csv")
plot_data <- transactions_df |>
count(State) |>
arrange(desc(n)) |>
slice_max(n, n = 20)
ggplot(plot_data, aes(x = reorder(State, n), y = n)) +
# main data
geom_bar(stat = "identity", fill = "#1B4242") +
coord_flip() +
# theme
dark_theme() +
# labels
labs(x = "State",
y = "Number of Trades",
title = "Top 20 States by Trade Counts")
plot_data <- transactions_df |>
drop_na(Issuer.Name) |>
count(Issuer.Name) |>
top_n(10, n) |>
arrange(desc(n))
ggplot(plot_data, aes(x = reorder(Issuer.Name, n), y = n)) +
# main data
geom_bar(stat = "identity", fill = "#1B4242") +
coord_flip() +
# theme
dark_theme() +
# labels
labs(title = "The Most Popular Stocks",
x = "Issuer Name",
y = "Count")
rnorm(n = 10, mean = 1, sd = 1)
x <- rnorm(n = 10, mean = 1, sd = 1)
var(x)
x <- rnorm(n = 10, mean = 1, sd = 1)
var(x)
x <- rnorm(n = 10, mean = 1, sd = 1)
var(x)
cal_var <- function(){
x <- rnorm(n = 10, mean = 1, sd = 1)
var(x)
}
results <- replicate(cal_var)
results <- replicate(cal_var, 100)
results <- replicate(100, cal_var)
cal_var <- function(){
x <- rnorm(n = 10, mean = 1, sd = 1)
return(var(x))
}
results <- replicate(100, cal_var)
View(results)
results <- replicate(100, cal_var())
mean(results)
x <- rnorm(n = 10, mean = 1, sd = 10)
var(x)
cal_var <- function(){
x <- rnorm(n = 10, mean = 1, sd = 10)
return(var(x))
}
results <- replicate(100, cal_var())
mean(results)
x <- pnorm(100)
x <- pnorm(100)
x <- pnorm(100)
x
x <- rnorm(100)
probs <- pnorm(x)
probs
qnorm(0.5)
qnorm(0.75)
p <- dnorm(x)
p
# load in the chicken diet data (save it in "d")
d <- read.table(file="/Users/xewe/Documents/Education/BS SJSU/Classes/MATH 167R - R Programming/RStudio/Data/ChickData.csv", header=T, sep=",")
# let's add the data into the "data view"
View(d)
# check the names, etc
names(d)
levels(d$feed)
# how many observations in each diet?
table(d$feed)
# let's look at a boxplot of weight gain by those 2 diets
boxplot(d$weight~d$feed, las=1, ylab="weight (g)",
xlab="feed",main="Weight by Feed")
# calculate the difference in sample MEANS
mean(d$weight[d$feed=="casein"])  # mean for casein
mean(d$weight[d$feed=="meatmeal"])  # mean for meatmeal
# lets calculate the absolute diff in means
test.stat1 <- abs(mean(d$weight[d$feed=="casein"]) -
mean(d$weight[d$feed=="meatmeal"]))
test.stat1
# calculate the difference in sample MEDIANS
median(d$weight[d$feed=="casein"])  # median for casein
median(d$weight[d$feed=="meatmeal"])  # median for meatmeal
# lets calculate the absolute diff in medians
test.stat2 <- abs(median(d$weight[d$feed=="casein"]) - median(d$weight[d$feed=="meatmeal"]))  #diff in medians
test.stat2
# for reproducability of results
set.seed(1979)
# the number of observations to sample
n <- length(d$feed)
# the number of permutation samples to take
P <- 100000
# the variable we will resample from
#     (note, could use the labels(feed) too, and "shuffle this")
variable <- d$weight
# initialize a matrix to store the permutation data
PermSamples <- matrix(0, nrow=n, ncol=P)
# now, get those permutation samples, using a loop
# let's take a moment to discuss what that code is doing...
for(i in 1:P){
PermSamples[,i] <- sample(variable, size= n, replace=FALSE)
}
# we can take a quick look at the first 5 columns of PermSamples
PermSamples[, 1:23]
# we can take a quick look at the first 5 columns of PermSamples
PermSamples[, 1:5]
# initialize vectors to store all of the Test-stats:
Perm.test.stat1 <- Perm.test.stat2 <- rep(0, P)
d$feed=="casein"
```{r, warning=FALSE, message=FALSE}
library(openxlsx)
library(tidyverse)
cpi <- read.xlsx("https://thedocs.worldbank.org/en/doc/1ad246272dbbc437c74323719506aa0c-0350012021/original/Inflation-data.xlsx",
sheet = 5)
cpi <- cpi[1:203,]
head(cpi)
graph_data <- cpi |>
pivot_longer(cols = `1970`:`2022`,
names_to = "Year",
values_to = "CPI") |>
mutate(Year = as.numeric(Year)) |>
filter(Country %in% c("United States", "Canada", "Mexico"))
ggplot(graph_data, mapping = aes(x = Year, y = CPI, color = Country)) +
geom_line()
library(tidyverse)
flips <- read_csv("https://math167r-s24.github.io/static/flips.csv")
head(flips)
flips_long <- flips |>
mutate(id = 1:200) |>
pivot_longer(-id,  names_to = "Sequence", values_to = "Flip")
library(tidyverse)
flips <- read_csv("https://math167r-s24.github.io/static/flips.csv")
head(flips)
flips_long <- flips |>
mutate(id = 1:200) |>
pivot_longer(-id,  names_to = "Sequence", values_to = "Flip")
long_flip_streaks <- flips_long |>
group_by(Sequence) |>
summarize(longest_streak = max(rle(Flip)$length))
long_sim_streaks <-
data.frame(
x = replicate(100000,
max(rle(sample(c("H", "T"), size = 200, replace = T))$length)
)
)
ggplot() +
geom_histogram(data = long_sim_streaks, aes(x = x), binwidth = 1) +
geom_vline(data = long_flip_streaks,
aes(color = Sequence, xintercept = longest_streak)) +
xlab("Longest Streak")
long_p_vals <- sapply(long_flip_streaks$longest_streak,
function (x) mean(long_sim_streaks$x < x))
print(long_p_vals)
long_dist_from_center <- abs(long_p_vals - 0.5)
print("Sample closest to simulated distribution: ")
c('A', 'B', 'C', 'D', 'E')[which.min(long_dist_from_center)]
avg_flip_streaks <- flips_long |>
group_by(Sequence) |>
summarize(avg_streak = mean(rle(Flip)$length))
avg_sim_streaks <-
data.frame(
x = replicate(100000,
mean(rle(sample(c("H", "T"), size = 200, replace = T))$length)
)
)
ggplot() +
geom_histogram(data = avg_sim_streaks, aes(x = x)) +
geom_vline(data = avg_flip_streaks,
aes(color = Sequence, xintercept = avg_streak)) +
xlab("Average Streak")
avg_p_vals <- sapply(avg_flip_streaks$avg_streak,
function (x) mean(avg_sim_streaks$x < x))
print(avg_p_vals)
avg_dist_from_center <- abs(avg_p_vals - 0.5)
print("Sample closest to simulated distribution: ")
c('A', 'B', 'C', 'D', 'E')[which.min(avg_dist_from_center)]
trans_counts <- flips_long |>
group_by(Sequence) |>
summarize(transitions = length(rle(Flip)$length))
trans_counts_sim <-
data.frame(
x = replicate(100000,
length(rle(sample(c("H", "T"), size = 200, replace = T))$length)
)
)
ggplot() +
geom_histogram(data = trans_counts_sim, aes(x = x)) +
geom_vline(data = trans_counts,
aes(color = Sequence, xintercept = transitions)) +
xlab("H/T Transitions")
trans_p_vals <- sapply(trans_counts$transitions,
function (x) mean(trans_counts_sim$x < x))
print(trans_p_vals)
trans_dist_from_center <- abs(trans_p_vals - 0.5)
print("Sample closest to simulated distribution: ")
c('A', 'B', 'C', 'D', 'E')[which.min(trans_dist_from_center)]
library(tidyverse)
library(ggplot2)
library(palmerpenguins)
data(penguins)
hist(
penguins$bill_length_mm,
main = 'Distribution of Bill Length',
xlab = 'Bill Length, mm',
ylab = 'Occurrences',
col = 'green'
)
ggplot(data = penguins,
aes(x = bill_length_mm)) +
geom_histogram(binwidth=1) +
xlab('Bill Length, mm') +
ylab('Occurrences') +
ggtitle('Distribution of Bill Length') +
theme(plot.title = element_text(hjust = 0.5))+
scale_x_continuous(breaks = seq(30, 60, by = 5))
plot(
x = penguins$bill_length_mm,
y = penguins$bill_depth_mm,
main = 'Bill Length vs Depth',
xlab = 'Bill Length, mm',
ylab = 'Bill Depth, mm',
col = 'blue',
)
ggplot(data = penguins,
aes(x = bill_length_mm, y = bill_depth_mm)) +
geom_point(color = 'red', alpha = 0.5)  +
xlab('Bill Length, mm') +
ylab('Bill Depth, mm') +
ggtitle('Bill Length vs Depth')+
theme(plot.title = element_text(hjust = 0.5))
ggplot(data = penguins,
aes(x = bill_length_mm, y = bill_depth_mm, color=species)) +
geom_point(alpha = 0.5)  +
xlab('Bill Length, mm') +
ylab('Bill Depth, mm') +
ggtitle('Bill Length vs Depth')+
theme(plot.title = element_text(hjust = 0.5))
rent <- readr::read_csv('https://raw.githubusercontent.com/rfordatascience/tidytuesday/master/data/2022/2022-07-05/rent.csv')
summary(rent)
head(rent)
sc_onebed <- rent |> filter(beds == 1, county == 'santa clara')
print(paste(nrow(sc_onebed), 'one bedroom listings in Santa Clara county'))
sc_onebed_2018 <- rent |> filter(beds == 1, county == 'santa clara', year == 2018)
print(paste('Median price for a 1 bedroom listing in Santa Clara county in 2018 is $',
median(sc_onebed_2018$price)))
county_medians <- rent |> filter(beds == 1, year == 2018) |>
group_by(county) |>
summarize(median_price = median(price))
most_expesive_county <- county_medians[which.max(county_medians$median_price), ]
print(paste('Most expensive county:', most_expesive_county[, 'county']))
print(paste('With median price for a 1 bedroom in 2018: $',
most_expesive_county[, 'median_price']))
sc_onebed_2005 <- rent |> filter(county == 'santa clara', beds == 1, year == 2005)
sc_onebed_2018 <- rent |> filter(county == 'santa clara', beds == 1, year == 2018)
ggplot(data = sc_onebed_2005,
aes(x = price)) +
geom_histogram(binwidth=50, fill='green', color = 'black') +
xlab('Price ($)') +
ylab('Occurrences') +
ggtitle('Santa Clara One Bedroom Rent in 2005') +
theme(plot.title = element_text(hjust = 0.5))
ggplot(data = sc_onebed_2018,
aes(x = price)) +
geom_histogram(binwidth=50, fill='red', color = 'black') +
xlab('Price ($)') +
ylab('Occurrences') +
ggtitle('Santa Clara One Bedroom Rent in 2018') +
theme(plot.title = element_text(hjust = 0.5))
sc_median_byyears <- rent |> filter(county == 'santa clara',
year >= 2000,
year <= 2018) |>
group_by(year) |>
summarize(median_price = median(price))
ggplot(sc_median_byyears,
aes(x = year, y = median_price)) +
geom_line() +
labs(title = 'Median Price for a 1 bedroom apartment for Santa Clara',
x = 'Year',
y = 'Price ($)') +
theme(plot.title = element_text(hjust = 0.5))
sc_median_byyears <- rent |> filter(county == 'santa clara',
year >= 2000,
year <= 2018) |>
group_by(city, year) |>
summarize(median_price = median(price))
ggplot(sc_median_byyears,
aes(x = year, y = median_price, color = city)) +
geom_line() +
labs(title = 'Median Price for a 1 bedroom apartment in Santa Clara County',
x = 'Year',
y = 'Price ($)') +
theme(plot.title = element_text(hjust = 0.5))
big_tech_stock_prices <- readr::read_csv('https://raw.githubusercontent.com/rfordatascience/tidytuesday/master/data/2023/2023-02-07/big_tech_stock_prices.csv')
summary(big_tech_stock_prices)
head(big_tech_stock_prices)
AAPL_IBM_NFLX_2010_2023 <- big_tech_stock_prices |> filter(stock_symbol %in% c('AAPL', 'IBM', 'NFLX'))
ggplot(AAPL_IBM_NFLX_2010_2023,
aes(x = date, y = close, color = stock_symbol)) +
geom_line() +
scale_x_date(date_breaks = '2 years', date_labels = '%Y') +  # Adjust this line for 2-year intervals
labs(title = 'Stock Prices Comparison',
x = 'Year',
y = 'Price ($)') +
theme(plot.title = element_text(hjust = 0.5))
AAPL_IBM_NFLX_covid <- AAPL_IBM_NFLX_2010_2023 |>
filter(date >= as.Date('2020-01-01') & date <= as.Date('2020-12-31'))
ggplot(AAPL_IBM_NFLX_covid,
aes(x = date, y = close, color = stock_symbol)) +
geom_line() +
scale_x_date(date_breaks = '1 month', date_labels = '%m',) +  # Adjusted for month labels
labs(title = 'Stock Prices Comparison during COVID',
x = 'Month',
y = 'Price ($)') +
theme(plot.title = element_text(hjust = 0.5))
companies <- c('Apple', 'IBM', 'Netflix')
prices_2014 <- AAPL_IBM_NFLX_2010_2023[AAPL_IBM_NFLX_2010_2023$date == as.Date('2014-01-10'), ]
prices_2022 <- AAPL_IBM_NFLX_2010_2023[AAPL_IBM_NFLX_2010_2023$date == as.Date('2022-01-10'), ]
percent_changes <- (prices_2022$close -
prices_2014$close) /
prices_2014$close * 100
prices_change <- data.frame(
company = companies,
price_2014 = prices_2014$close,
price_2022 = prices_2022$close,
percent_change = percent_changes
)
prices_change <- prices_change |> pivot_longer(
cols = starts_with('price'),
names_to = 'year',
names_prefix = 'price_',
values_to = 'price')
ggplot(prices_change, aes(x = company, y = price, fill = year)) +
geom_bar(stat = 'identity', position = position_dodge()) +
geom_text(data = subset(prices_change, year == '2022'),
aes(label = sprintf("%.1f%%", percent_change)),
position = position_dodge(width = 0.9), vjust = -0.2) +
labs(title = 'Growth Comparison 2014 to 2022', x = 'Company', y = 'Price ($)') +
theme(plot.title = element_text(hjust = 0.5))
sales_data <- read.csv("/Users/xewe/Documents/Education/BS SJSU/Classes/MATH 167R - R Programming/RStudio/Data/Assessor__Archived_05-11-2022__-_Residential_Sales_Data_20240313.csv")
dim(sales_data)
hist(sales_data$Sale.Price,
main = "Histogram of Sale Price",
xlab = "Sale Price ($)",
col = "green")
hist(sales_data$Sale.Price,
main = "Histogram of Sale Price",
xlab = "Sale Price ($)",
col = "green",
xlim = c(0, 2000000),
breaks = 1000)
clean_data <- subset(sales_data, Sale.Price >= 500)
clean_data$log_sale_price <- log(clean_data$Sale.Price)
price_bed <- subset(clean_data, Bedrooms <= 10)
price_bed$Bedrooms <- as.factor(price_bed$Bedrooms)
boxplot(log_sale_price ~ Bedrooms, data = price_bed,
xlab = "Bedrooms", ylab = "Log Sale Price",
main = "Log Sale Price by Number of Bedrooms",
col = "green", border = "blue")
clean_data$age_bin <- cut(clean_data$Age,
breaks = c(-Inf, 20, 40, 60, 80, 100, Inf),
labels = c("1-20", "21-40", "41-60", "61-80", "81-100", "100+"),
right = FALSE)
boxplot(log_sale_price ~ age_bin, data = clean_data,
xlab = "Property Age", ylab = "Log Sale Price",
main = "Log Sale Price by Property Age",
col = "green", border = "blue")
values_data <- read.csv("/Users/xewe/Documents/Education/BS SJSU/Classes/MATH 167R - R Programming/RStudio/Data/Assessor__Archived_05-11-2022__-_First_Pass_Values_20240313.csv")
dim(values_data)
combined_data <- merge(clean_data, values_data, by = "PIN")
combined_data <- combined_data[!is.na(combined_data$log_sale_price) & !is.na(combined_data$`First.Pass.Value.1`), ]
nrow(combined_data)
combined_data$log_first_pass_value_1 = log(combined_data$`First.Pass.Value.1`)
plot(combined_data$log_first_pass_value_1, combined_data$log_sale_price,
xlab = "Log First Pass 1 Value",
ylab = "Log Sale Price",
main = "Sale Price VS First Pass Value 1",
col = rgb(0, 0, 1, 0.2), pch = 16, cex = 0.4)
abline(a = 0, b = 1, col = "red")
#PS
#Chat GPT wrote code below
combined_data$Site.Desirability <- as.factor(combined_data$Site.Desirability)
levels(combined_data$Site.Desirability)
colors <- rainbow(length(levels(combined_data$Site.Desirability)))
plot(combined_data$log_first_pass_value_1,
combined_data$log_sale_price,
col = colors[as.numeric(combined_data$Site.Desirability)],
xlab = "first_pass_value_1_log",
ylab = "log_sale_price",
main = "Log of Sale Price vs. Log of First Pass Value 1",
pch = 16,  # Choose a plotting character
cex = 0.2) # Choose size of points
abline(a = 0, b = 1, col = "red")
legend("bottomright",
legend = levels(combined_data$Site.Desirability),
col = colors,
pch = 16)
run_one_sim <- function(seed, n_a, n_b){
set.seed(seed)
while(n_a > 0 & n_b > 0){
if(sample(c('H', 'T'), size = 1) == 'H'){
n_a = n_a + 1
n_b = n_b - 1
} else {
n_a = n_a - 1
n_b = n_b + 1
}
}
return(ifelse(n_b == 0, 'A', 'B'))
}
runs <- 1000
results <- c()
for(i in 1:runs){
results <- append(results, run_one_sim(i, 10, 10))
}
print(sprintf("A winrate: %.2f%%  |  B winrate: %.2f%%",
sum(results == 'A') / runs * 100,
sum(results == 'B') / runs * 100))
run_mult_sim <- function(runs, n_a, n_b){
results <- c()
for(i in 1:runs){
seed <- sample(1:1000000, size = 1)
results <- append(results, run_one_sim(seed, n_a, n_b))
}
return(paste('A:', sum(results == 'A') / runs * 100, '% B:', sum(results == 'B') / runs * 100, '%'))
}
mat <- matrix(0, 5, 5)
for(i in 1:5){
for(j in 1:5){
mat[i, j] <- run_mult_sim(10000, i, j)
}
}
mat
mystery_fn <- function(a, b) {
if (length(a) != length(b)) {
stop("Inputs must have same length.")
}
out <- numeric(length(a))
for (i in 1:length(a)) {
if (a[i] > b[i]) {
out[i] <- a[i]
} else {
out[i] <- a[i] + b[i]
}
}
return(out)
}
mystery_fn(4,5)
mystery_fn(c(1, 2, 3), c(1, 1, 1))
mystery_fn(c(1, 2, 3), c(1, 1, 1))
A <- matrix(c(1, 1, 2, 6, 2, 2, 3, 6, 3, 3, 4, 6, 4, 4, 5, 6), nrow = 4, byrow = TRUE)
current <- 0
for (j in 1:4) {
for (i in 1:4) {
if (A[i, j] > current) {
print(A[i, j])
current <- A[i, j]
}
}
}
mystery_fn(c(1, 2, 3), c(1, 1, 1))
