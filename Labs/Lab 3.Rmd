---
title: "Lab 3: Descriptive Statistics"
author: "Maxim Dokukin"
date: 2024-02-13
format: 
  html:
    embed-resources: true
    code-tools: true
    code-summary: "Code"

---

**Follow the instructions below and use R Markdown to create a pdf document with your code and answers to the following questions on Gradescope.** You may find a template file by clicking "Code" in the top right corner of this page.

Your final submission should clearly include all code needed to generate your answers and should be formatted according to the guidelines outlined in class. In particular, make sure:

1. Code and output are clearly organized by question.
2. Unnecessary messages, warning, and output are removed.

You may collaborate with your classmates and consult external resources, but you should write and submit your own answer. **Any classmates with whom you collaborate should be credited at the top of your submission. Similarly, if you consult any external references, you should cite them clearly and explicitly.**

## A. Weather Forecast Data

1.  For this lab, we'll be using data on weather forecasts gathered by student at Saint Louis University. You can read about the dataset [here](https://github.com/rfordatascience/tidytuesday/tree/master/data/2022/2022-12-20). Download the weather forecasts data using the following code:

```{r, warning=FALSE, message=FALSE}
weather_forecasts <- readr::read_csv('https://raw.githubusercontent.com/rfordatascience/tidytuesday/master/data/2022/2022-12-20/weather_forecasts.csv')
summary(weather_forecasts)
```



2.  How many rows are in this dataset? How many columns?

```{r, warning=FALSE, message=FALSE}
dim(weather_forecasts)
```

651968 rows, 10 clos.



3.  How many cities are represented in this dataset?

```{r, warning=FALSE, message=FALSE}
length(unique(weather_forecasts$city))
```

160 cities = size of array with unique cities.



4.  Create a new data frame containing only the forecasts for San Jose. You may have to explore the values for the `city` variable.

```{r, warning=FALSE, message=FALSE}
san_jose_data = weather_forecasts[weather_forecasts$city == 'SAN_JOSE', ]
```

15 min wasted on realizing its san_jose, not san jose.



5. Compute the mean absolute error between `observed_temp` and `forecast_temp` for San Jose.

```{r, warning=FALSE, message=FALSE}
san_jose_data$absolute_error <- abs(san_jose_data$observed_temp - 
                                    san_jose_data$forecast_temp)
mean_error <- mean(san_jose_data$absolute_error, na.rm = TRUE)
print(mean_error)
```

2.169762



6. Compute the mean absolute error between `observed_temp` and `forecast_temp` for San Jose using only forecasts made 48 hours in advance.

```{r, warning=FALSE, message=FALSE}
san_jose_48adv_data = san_jose_data[san_jose_data$forecast_hours_before == 48,]
  
san_jose_48adv_data$absolute_error <- abs(san_jose_48adv_data$observed_temp - 
                                            san_jose_48adv_data$forecast_temp)
mean_error_48 <- mean(san_jose_48adv_data$absolute_error, na.rm = TRUE)
print(mean_error_48)
```

2.262544



7. Compute the mean absolute error between `observed_temp` and `forecast_temp` for San Jose using only forecasts made 12 hours in advance.

```{r, warning=FALSE, message=FALSE}
san_jose_12adv_data = san_jose_data[san_jose_data$forecast_hours_before == 12,]
  
san_jose_12adv_data$absolute_error <- abs(san_jose_12adv_data$observed_temp - 
                                            san_jose_12adv_data$forecast_temp)
mean_error_12 <- mean(san_jose_12adv_data$absolute_error, na.rm = TRUE)
print(mean_error_12)
```

2.0553



8. Compare your answers to 6 and 7. What do you notice? How does this compare to your expectation?

24h advance forecasts have smaller error. 
This makes sense, as it is easier to make more accurate predictions in the short term.



9. Pick two cities in this dataset. Investigate whether the forecast accuracy is better for one city than for the other, using an appropriate statistic. Discuss your findings.

```{r, warning=FALSE, message=FALSE}
nyc_data = weather_forecasts[weather_forecasts$city == 'NEW_YORK_CITY', ]
nyc_data$absolute_error <- abs(nyc_data$observed_temp - nyc_data$forecast_temp)
nyc_mean_error <- mean(nyc_data$absolute_error, na.rm = TRUE)
print(nyc_mean_error)

gf_data = weather_forecasts[weather_forecasts$city == 'GREAT_FALLS', ]
gf_data$absolute_error <- abs(gf_data$observed_temp - gf_data$forecast_temp)
gf_mean_error <- mean(gf_data$absolute_error, na.rm = TRUE)
print(gf_mean_error)
```

Great Falls accuracy is significantly lower than in NYC. 
Maybe there are more variables that effect weather there?
Yet, the best advice to avoid rain is the same, 'Take the umbrella'



## B. Find your own data

For this component, pick a [Tidy Tuesday dataset](https://github.com/rfordatascience/tidytuesday/tree/master/data/2023) and complete the following activity.

10. Provide a brief description of your dataset. Identify at least two questions you could try to answer using this dataset.

```{r, warning=FALSE, message=FALSE}
library(tidyverse)

big_tech_stock_prices <- readr::read_csv('https://raw.githubusercontent.com/rfordatascience/tidytuesday/master/data/2023/2023-02-07/big_tech_stock_prices.csv')

summary(big_tech_stock_prices)
```

Stock prices from 2010 to 2023 for big tech.

- What was the most growing stock from Jan 10 2014 to Jan 10 2022 (%)?

- What was the least growing stock from Jan 10 2012 to Jan 10 2022 (%)?

- What is the average (median) growth from Jan 10 2014 to Jan 10 2022 (%)?


PS I was trying Jan 1st, but realized stocks dont trade this day because of the holiday.
Jan 10 2015 had no data either.
Meta has not been on data set in 2010...
had to adjust my date range to make sure I have all the numbers.

11. Open your dataset in R and compute one or more descriptive statistics that shed light on your questions. Discuss your findings.

```{r, warning=FALSE, message=FALSE}

companies <- unique(big_tech_stock_prices$stock_symbol)
prices_2014 <- big_tech_stock_prices[big_tech_stock_prices$date == as.Date('2014-01-10'), ]
prices_2022 <- big_tech_stock_prices[big_tech_stock_prices$date == as.Date('2022-01-10'), ]

prices_change <- data.frame(
  companies,
  prices_2014$close,
  prices_2022$close
)

prices_change$percent_change = (prices_change$prices_2022.close - 
                                   prices_change$prices_2014.close) / 
                                   prices_change$prices_2014.close * 100
colnames(prices_change) <- c('company', 'price_2014', 'price_2022', 'percent_change')
```

Best performer 2014-2022
```{r, warning=FALSE, message=FALSE}
prices_change[which.max(prices_change$percent_change), ][1,]
```

Worst performer 2014-2022
```{r, warning=FALSE, message=FALSE}
prices_change[which.min(prices_change$percent_change), ]
```

Median growth rate 2014 - 2022
```{r, warning=FALSE, message=FALSE}
median(prices_change$percent_change)
```





12. Are there any limitations of your analysis? Could additional data or more complicated methods improve your analysis? Discuss.

I wanted to do Jan 1 2010 to Jan 1 2020. But, for Jan 1 there is no data. 
META also had no data for the early years.
I had to adjust my date range to fit these limitations.
Using the last value in the previous year before Jan 1, 
could have made possible data analysis in the range Jan 1, YYYY - Jan 1, YYYY
